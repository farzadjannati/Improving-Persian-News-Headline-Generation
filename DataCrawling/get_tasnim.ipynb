{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "323c0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "KEYWORDS = {\"ببینید\", \"فیلم\", \"عکس\", \"ویدیو\", \"ویدئو\", \"تصاویر\", \"تصاویری\"}\n",
    "\n",
    "def _normalize_persian(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    return (text.replace(\"ي\", \"ی\")\n",
    "                .replace(\"ك\", \"ک\")\n",
    "                .replace(\"ۀ\", \"ه\"))\n",
    "\n",
    "def read_existing_news_ids(csv_file: str) -> set:\n",
    "    if not os.path.isfile(csv_file):\n",
    "        return set()\n",
    "\n",
    "    existing_ids = set()\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader, None)\n",
    "        if header:\n",
    "            news_id_index = header.index(\"news_id\") if header else 0\n",
    "\n",
    "        else:\n",
    "            print(\"Header is missing.\")\n",
    "            return set()\n",
    "\n",
    "        for row in reader:\n",
    "            if len(row) > news_id_index:\n",
    "                existing_ids.add(row[news_id_index])\n",
    "    \n",
    "    return existing_ids\n",
    "\n",
    "\n",
    "def get_news(url: str) -> str:\n",
    "    r = requests.get(url, allow_redirects=True, timeout=20)\n",
    "\n",
    "    # Check if the HTTP status code is 404\n",
    "    if \"صفحه مورد نظر یافت نشد\" in BeautifulSoup(r.text, 'html.parser').find('title').get_text(strip=True):\n",
    "        print(f\"Skipped: {url} - 404 Not Found\")\n",
    "        return None  # Skip if 404 error\n",
    "    \n",
    "    if r.history:\n",
    "        if not r.url.startswith(\"https://www.tasnimnews.com/fa/news/\"):\n",
    "            print(f\"Redirected to a different URL: {r.url}\")\n",
    "            return None\n",
    "\n",
    "    r.raise_for_status()  # Raise an exception for other HTTP errors\n",
    "    return r.text\n",
    "\n",
    "def parse_news_html(html: str):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # news_id\n",
    "    script_tag = soup.find('script', string=re.compile(r\"const\\s+id\\s*=\\s*'\\d+'\"))\n",
    "    news_id = re.search(r\"const\\s+id\\s*=\\s*'(\\d+)'\", script_tag.string).group(1) if script_tag else \"\"\n",
    "\n",
    "    # category\n",
    "    ul_tag = soup.find(\"ul\", class_=\"list-inline details\")\n",
    "    if ul_tag == None:\n",
    "        category = None\n",
    "        date = None\n",
    "    else:\n",
    "        category = _normalize_persian(ul_tag.find(\"li\", class_=\"service\").find(\"a\").get_text(strip=True)) if ul_tag.find(\"li\", class_=\"service\") else \"\"\n",
    "\n",
    "    # date\n",
    "        date = _normalize_persian(ul_tag.find(\"li\", class_=\"time\").get_text(strip=True)) if ul_tag.find(\"li\", class_=\"time\") else \"\"\n",
    "\n",
    "    # url + title\n",
    "    a_title = soup.find(\"h1\", class_=\"title\")\n",
    "    meta_tag = soup.find(\"meta\", property=\"og:url\") if soup else None\n",
    "    url = (\"https:\" + meta_tag[\"content\"]) if meta_tag and meta_tag.has_attr(\"content\") else \"\"\n",
    "    title = _normalize_persian(a_title.get_text(strip=True)) if a_title else \"\"\n",
    "\n",
    "    # introtext\n",
    "    intro = soup.find(\"h3\", class_=\"lead\")\n",
    "    introtext = _normalize_persian(intro.get_text(\" \", strip=True)) if intro else \"\"\n",
    "\n",
    "    text_lines = []\n",
    "    article_tag = soup.find('article', class_='single-news')\n",
    "\n",
    "    if article_tag:\n",
    "        for p_tag in soup.find_all('p'):\n",
    "            txt = p_tag.get_text(\" \", strip=True)\n",
    "\n",
    "            if not txt or txt == '&nbsp;':\n",
    "                continue\n",
    "            \n",
    "            if p_tag.find_parent('div', class_='markup-container readmore-container'):\n",
    "                continue\n",
    "    \n",
    "            text_lines.append(_normalize_persian(txt))\n",
    "\n",
    "    # delete last <p> without any info\n",
    "    if text_lines and re.search(r\"انتهای پیام/.*\", text_lines[-1]):\n",
    "        text_lines = text_lines[:-1]\n",
    "\n",
    "    # text = \"\\n\".join(text_lines)\n",
    "    text = \" [n] \".join(text_lines)\n",
    "    \n",
    "    # tags\n",
    "    script_tag = soup.find('script', type='application/ld+json')\n",
    "\n",
    "    if script_tag:\n",
    "        json_data = json.loads(script_tag.string)\n",
    "        tags = json_data.get(\"keywords\", \"\") if \"keywords\" in json_data else \"\"\n",
    "    else:\n",
    "        tags = \"\"\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"news_id\": news_id,\n",
    "        \"category\": category,\n",
    "        \"date\": date,\n",
    "        \"url\": url,\n",
    "        \"title\": title,\n",
    "        \"introtext\": introtext,\n",
    "        \"text\": text,\n",
    "        \"tags\": tags,\n",
    "    }\n",
    "\n",
    "def _should_skip(row_dict: dict) -> bool:\n",
    "    \"\"\"Condition for completely skipping the news from CSV\"\"\"\n",
    "\n",
    "    title = row_dict.get(\"title\", \"\") or \"\"\n",
    "    text = row_dict.get(\"text\", \"\") or \"\"\n",
    "    introtext = row_dict.get(\"introtext\", \"\") or \"\"\n",
    "\n",
    "    # Condition 1: Forbidden words in the title\n",
    "    if any(kw in title for kw in KEYWORDS):\n",
    "        return True\n",
    "\n",
    "    # Condition 2: Empty introtext\n",
    "    if not introtext.strip():\n",
    "        return True\n",
    "\n",
    "    # Condition 3: Text word count less than 10\n",
    "    word_count = len(re.findall(r\"\\S+\", text))\n",
    "    if word_count < 10:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def write_news_csv(row_dict: dict, csv_file: str = \"news.csv\"):\n",
    "    category = row_dict.get(\"category\", \"\").strip()\n",
    "    if not category:\n",
    "        print(f\"Skipped: {row_dict.get(\"news_id\", \"\").strip()} ({row_dict.get(\"title\", \"\").strip()}) Category is empty.\")\n",
    "        return\n",
    "    \n",
    "    tag = row_dict.get(\"tags\", \"\").strip()\n",
    "    if not tag:\n",
    "        print(f\"Skipped: {row_dict.get(\"news_id\", \"\").strip()} ({row_dict.get(\"title\", \"\").strip()}) Tags is empty.\")\n",
    "        return\n",
    "    headers = [\"news_id\", \"category\", \"date\", \"url\", \"title\", \"introtext\", \"text\", \"tags\"]\n",
    "    file_exists = os.path.isfile(csv_file)\n",
    "    need_header = (not file_exists) or os.path.getsize(csv_file) == 0\n",
    "\n",
    "    with open(csv_file, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if need_header:\n",
    "            w.writerow(headers)\n",
    "        w.writerow([row_dict.get(h, \"\") for h in headers])\n",
    "\n",
    "def parse_news_from_url(url: str, csv_file: str = \"news.csv\", news_id: str = \"\"):\n",
    "    # Checking news_id's in CSV\n",
    "    existing_ids = read_existing_news_ids(csv_file)\n",
    "\n",
    "    if str(news_id) in existing_ids:\n",
    "        print(f\"Existed: {news_id} - Already exists in CSV.\")\n",
    "        return None\n",
    "    \n",
    "    html = get_news(url)\n",
    "\n",
    "    if html is None:\n",
    "        return None\n",
    "    \n",
    "    row = parse_news_html(html)\n",
    "\n",
    "    if _should_skip(row):\n",
    "        print(f\"Skipped: {row['news_id']} ({row['title']})\")\n",
    "        return None\n",
    "\n",
    "    write_news_csv(row, csv_file)\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7054428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped: 3392500 (طرح جدید فروش لاماری ایما با پنج رنگ متنوع) Tags is empty.\n",
      "Skipped: 3392508 (صهیونیست‌ها برای فرار و گرفتن گذرنامه خود را به آب و آتش می زنند) Tags is empty.\n",
      "Redirected to a different URL: https://www.tasnimnews.com/he/news/2025/09/05/3392516/%D7%91%D7%99%D7%9F-%D7%94%D7%A4%D7%A6%D7%95%D7%A2%D7%99%D7%9D-%D7%AA%D7%99%D7%A0%D7%95%D7%A7-20-%D7%A0%D7%A4%D7%92%D7%A2%D7%99%D7%9D-%D7%91%D7%9E%D7%AA%D7%A7%D7%A4%D7%AA-%D7%9E%D7%AA%D7%A0%D7%97%D7%9C%D7%99%D7%9D-%D7%A2%D7%9C-%D7%97-%D7%9C%D7%AA-%D7%90-%D7%93%D7%91%D7%A2-%D7%91%D7%93%D7%A8%D7%95%D7%9D-%D7%94%D7%A8-%D7%97%D7%91%D7%A8%D7%95%D7%9F\n",
      "Skipped: 3392540 (آغاز عملیات آب‌رسانی به ۱۰ روستای دلفان) Tags is empty.\n",
      "Skipped: 3392564 (تمسک به ولایت فقیه محور تحقق اتحاد و انسجام در جامعه است) Tags is empty.\n",
      "Redirected to a different URL: https://www.tasnimnews.com/ar/news/2025/09/05/3392572/%D8%AE%D8%B7%DB%8C%D8%A8-%D8%AC%D9%85%D8%B9%D8%A9-%D8%B7%D9%87%D8%B1%D8%A7%D9%86-%D8%B2%DB%8C%D8%A7%D8%B1%D8%A9-%D8%A7%D9%84%D8%B1%D8%A6%DB%8C%D8%B3-%D8%A7%D9%84%D8%A5%DB%8C%D8%B1%D8%A7%D9%86%DB%8C-%D8%A5%D9%84%D9%89-%D8%A7%D9%84%D8%B5%DB%8C%D9%86-%DA%A9%D8%A7%D9%86%D8%AA-%D9%85%D9%86-%D8%A3%D8%A8%D8%B1%D8%B2-%D8%A7%D9%84%D9%85%D8%B3%D8%A7%D8%B1%D8%A7%D8%AA-%D8%A7%D9%84%D8%AF%D8%A8%D9%84%D9%88%D9%85%D8%A7%D8%B3%DB%8C%D8%A9\n",
      "Redirected to a different URL: https://www.tasnimnews.com/fa/media/1404/06/14/3392588/%D9%86%D8%AE%D8%B3%D8%AA%DB%8C%D9%86-%D9%87%D9%85%D8%A7%DB%8C%D8%B4-%D9%85%D9%84%DB%8C-%D8%B1%D8%A7%D8%B2-%D8%B1%D8%B4%DB%8C%D8%AF-%D8%AF%D8%B1-%D8%AF%D8%B2%D9%81%D9%88%D9%84-%D8%A8%D8%B1%DA%AF%D8%B2%D8%A7%D8%B1-%D8%B4%D8%AF\n",
      "Skipped: 3392596 (سوانح رانندگی بازهم جان گرفت؛ فوت ۲ نفر در حوادث رانندگی در استان مرکزی) Tags is empty.\n",
      "Skipped: 3392604 (محموله‌های بزرگ و میلیاردی قاچاق در استان مرکزی کشف و ضبط شد) Tags is empty.\n",
      "Skipped: 3392612 (امانی: فعال‌سازی مکانیسم ماشه، امنیت انرژی و ثبات منطقه را به مخاطره می‌اندازد) Tags is empty.\n",
      "Redirected to a different URL: https://www.tasnimnews.com/tr/news/2025/09/05/3392620/iran-uaea-g%C3%B6r%C3%BC%C5%9Fmeleri-bug%C3%BCn-viyana-da-ba%C5%9Fl%C4%B1yor\n",
      "Redirected to a different URL: https://www.tasnimnews.com/ar/news/2025/09/05/3392636/40-%D8%A3%D9%84%D9%81%D9%8B%D8%A7-%DB%8C%D8%A4%D8%AF%D9%88%D9%86-%D8%B5%D9%84%D8%A7%D8%A9-%D8%A7%D9%84%D8%AC%D9%85%D8%B9%D8%A9-%D9%81%DB%8C-%D8%A7%D9%84%D8%A3%D9%82%D8%B5%D9%89\n",
      "Redirected to a different URL: https://www.tasnimnews.com/ru/news/2025/09/05/3392660/%D0%BF%D0%BE%D1%87%D0%B5%D0%BC%D1%83-%D1%8D%D1%80%D0%B4%D0%BE%D0%B3%D0%B0%D0%BD-%D1%85%D0%BE%D1%87%D0%B5%D1%82-%D0%B2%D0%B5%D1%80%D0%BD%D1%83%D1%82%D1%8C-%D0%BA%D1%8B%D0%BB%D1%8B%D1%87%D0%B4%D0%B0%D1%80%D0%BE%D0%B3%D0%BB%D1%83\n",
      "Redirected to a different URL: https://www.tasnimnews.com/en/news/2025/09/05/3392676/thailand-s-anutin-charnvirakul-elected-pm-after-rout-of-ruling-party-rival\n",
      "Redirected to a different URL: https://www.tasnimnews.com/en/news/2025/09/05/3392692/us-deploying-10-fighter-jets-to-puerto-rico-for-drug-cartel-fight\n",
      "Skipped: 3392716 (احداث زیرگذر عابرپیاده در ایستگاه قطار نسیم‌شهر کلید خورد) Tags is empty.\n",
      "Redirected to a different URL: https://www.tasnimnews.com/en/news/2025/09/06/3392724/iran-wins-eight-medals-at-akf-cadet-junior-u-21-championships\n",
      "Redirected to a different URL: https://www.tasnimnews.com/ar/news/2025/09/05/3392732/%D9%84%D8%AC%D8%A7%D9%86-%D8%A7%D9%84%D9%85%D9%82%D8%A7%D9%88%D9%85%D8%A9-%D8%AA%D9%87%D8%AF%DB%8C%D8%AF%D8%A7%D8%AA-%DA%A9%D8%A7%D8%AA%D8%B3-%D8%AF%D8%B9%D9%88%D8%A9-%D8%B5%D8%B1%DB%8C%D8%AD%D8%A9-%D9%84%D9%84%D8%A5%D8%A8%D8%A7%D8%AF%D8%A9-%D9%88%D8%A7%D9%84%D8%AA%D8%B7%D9%87%DB%8C%D8%B1-%D8%A7%D9%84%D8%B9%D8%B1%D9%82%DB%8C-%D9%81%DB%8C-%D8%BA%D8%B2%D8%A9\n",
      "Redirected to a different URL: https://www.tasnimnews.com/ar/news/2025/09/05/3392740/%D9%87%DB%8C%D8%A6%D8%A9-%D8%A7%D9%84%D8%A3%D8%B3%D8%B1%D9%89-%D8%A7%D9%84%D9%81%D9%84%D8%B3%D8%B7%DB%8C%D9%86%DB%8C%DB%8C%D9%86-%D8%A7%D9%84%D9%85%D8%AD%D8%A7%DA%A9%D9%85-%D8%A7%D9%84%D8%B9%D8%B3%DA%A9%D8%B1%DB%8C%D8%A9-%D8%AA%D8%B9%D8%B1%D9%82%D9%84-%D8%A5%D8%AC%D8%B1%D8%A7%D8%A1%D8%A7%D8%AA-%D8%A7%D9%84%D8%A5%D9%81%D8%B1%D8%A7%D8%AC-%D8%B9%D9%86-%D8%A7%D9%84%D8%A3%D8%B3%D8%B1%D9%89\n",
      "Skipped: https://www.tasnimnews.com/3392748 - 404 Not Found\n",
      "Skipped: 3392756 (مالک تراکتور: احتمال محرومیت سپاهان بالاست/ دروازه‌بان خارجی جذب شد) Tags is empty.\n",
      "Redirected to a different URL: https://www.tasnimnews.com/ar/news/2025/09/05/3392772/%D8%B9%D8%B1%D8%A7%D9%82%D8%AC%DB%8C-%D8%B5%D9%85%D8%AA-%D8%A7%D9%84%D8%BA%D8%B1%D8%A8-%D8%AA%D8%AC%D8%A7%D9%87-%D8%AA%D8%B1%D8%B3%D8%A7%D9%86%D8%A9-%D8%A5%D8%B3%D8%B1%D8%A7%D8%A6%DB%8C%D9%84-%D8%A7%D9%84%D9%86%D9%88%D9%88%DB%8C%D8%A9-%DB%8C%D8%B3%D9%82%D8%B7-%D8%B4%D8%B1%D8%B9%DB%8C%D8%AA%D9%87-%D9%81%DB%8C-%D8%B7%D8%B1%D8%AD-%D9%85%D9%88%D8%B6%D9%88%D8%B9-%D8%B9%D8%AF%D9%85-%D8%A7%D9%84%D8%A7%D9%86%D8%AA%D8%B4%D8%A7%D8%B1\n",
      "Skipped: 3392788 (ارتقای جایگاه بدمینتون گیلان در سطح ملی از رتبه ۲۴ به رتبه ۸) Tags is empty.\n",
      "Skipped: https://www.tasnimnews.com/3392796 - 404 Not Found\n",
      "Skipped: https://www.tasnimnews.com/3392804 - 404 Not Found\n",
      "Skipped: https://www.tasnimnews.com/3392812 - 404 Not Found\n",
      "Skipped: https://www.tasnimnews.com/3392828 - 404 Not Found\n",
      "Skipped: 3392836 (برگزاری بزرگترین مولودی‌خوانی کشور در سنندج/شمس قریشی که بود؟) Tags is empty.\n",
      "Skipped: https://www.tasnimnews.com/3392844 - 404 Not Found\n",
      "Skipped: https://www.tasnimnews.com/3392852 - 404 Not Found\n",
      "Skipped: 3392884 (اجرای طرح مهارت‌آموزی تا اشتغال سربازان از هفته اول مهر در استان مرکزی) Tags is empty.\n",
      "Skipped: 3392892 (بلاگر هتاک به اقوام در ایذه بازداشت شد) Tags is empty.\n",
      "Skipped: https://www.tasnimnews.com/3392900 - 404 Not Found\n",
      "Skipped: 3392916 (جانشین فراجا: دشمنان ایران ‌در تلاشند ‌آرامش مرزهای شرقی ‌را بهم بزنند) Tags is empty.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_id = 3392500\n",
    "    end_id   = 3392930\n",
    "    csv_file = \"news_tasnim_20.csv\"\n",
    "\n",
    "    for news_id in range(start_id, end_id + 1, 8):\n",
    "        url = f\"https://www.tasnimnews.com/{news_id}\"\n",
    "        parse_news_from_url(url, csv_file, news_id)\n",
    "        # try:\n",
    "        #     data = parse_news_from_url(url, csv_file, news_id)\n",
    "        #     print(f\"Done {news_id}\")\n",
    "        #     for k, v in data.items():\n",
    "        #         print(f\"{k}: {v}\")\n",
    "        #     print(\"-\" * 50)\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error in {news_id}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
